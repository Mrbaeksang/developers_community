import { PrismaClient, PostStatus, GlobalRole } from '@prisma/client'

const prisma = new PrismaClient()

async function createOpenR1ReasoningAiPost() {
  const categoryId = 'cme5a7but0004u8ww8neir3k3' // ì˜¤í”ˆì†ŒìŠ¤ ì¹´í…Œê³ ë¦¬
  const authorId = 'cmdri2tj90000u8vgtyir9upy' // ê´€ë¦¬ì ì‚¬ìš©ì

  // ëœë¤ ì¡°íšŒìˆ˜ ìƒì„± í•¨ìˆ˜ (ì˜¤í”ˆì†ŒìŠ¤: 150-300)
  const getRandomViewCount = (min: number, max: number) =>
    Math.floor(Math.random() * (max - min + 1)) + min

  const title =
    'ğŸ¤– Open R1: Hugging Faceê°€ DeepSeek R1ì„ ì™„ì „ ì¬í˜„! 25K+ ìŠ¤íƒ€ íˆ¬ëª… AI'

  const content = `# ğŸ¤– Open R1: Hugging Faceê°€ ë§Œë“  DeepSeek R1 ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ ì¬í˜„! íˆ¬ëª…í•œ ì¶”ë¡  ê³¼ì •ìœ¼ë¡œ AI ë¯¼ì£¼í™”

**2025ë…„ AI ì˜¤í”ˆì†ŒìŠ¤ í˜ì‹ ** - **Hugging Face Open R1**ì´ DeepSeek R1ì˜ ì™„ì „í•œ ì˜¤í”ˆì†ŒìŠ¤ ì¬í˜„ì„ ëª©í‘œë¡œ í•˜ë©° **GitHub 25.2K+ ìŠ¤íƒ€**ë¥¼ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤. íˆ¬ëª…í•˜ê³  ì ‘ê·¼ ê°€ëŠ¥í•œ AI ì¶”ë¡  ëª¨ë¸ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸš€ Open R1ì´ í•´ê²°í•˜ëŠ” AIì˜ ë¸”ë™ë°•ìŠ¤ ë¬¸ì œ

### **ê¸°ì¡´ AI ì¶”ë¡  ëª¨ë¸ì˜ í•œê³„**
- ğŸ”’ **ë¸”ë™ë°•ìŠ¤**: ì¶”ë¡  ê³¼ì •ì„ ì•Œ ìˆ˜ ì—†ìŒ
- ğŸ’° **ë¹„ìš© ì¥ë²½**: ìƒì—…ì  API ì˜ì¡´ì„±
- ğŸ¢ **ê¸°ì—… ë…ì **: ì†Œìˆ˜ ê¸°ì—…ì˜ ê¸°ìˆ  ë…ì 
- âš–ï¸ **ì‹ ë¢°ì„± ë¶€ì¡±**: ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ ê²°ì • ê³¼ì •

### **Open R1ì˜ í˜ì‹ ì  í•´ê²°ì±…**
- ğŸŒŸ **ì™„ì „ íˆ¬ëª…**: ëª¨ë“  ì¶”ë¡  ê³¼ì • ê³µê°œ
- ğŸ†“ **ë¬´ë£Œ ì ‘ê·¼**: ëˆ„êµ¬ë‚˜ ì‚¬ìš© ê°€ëŠ¥
- ğŸ”“ **ì˜¤í”ˆì†ŒìŠ¤**: ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ê°œë°œ
- ğŸ” **ê²€ì¦ ê°€ëŠ¥**: ëª¨ë“  ë‹¨ê³„ ì¶”ì  ê°€ëŠ¥

## ğŸ§  Open R1ì˜ í•µì‹¬ ì¶”ë¡  ë©”ì»¤ë‹ˆì¦˜

### **Chain-of-Thought (CoT) ì¶”ë¡ **
\`\`\`python
from open_r1 import ReasoningModel

model = ReasoningModel()

# ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œ í•´ê²°
problem = "í•œ íšŒì‚¬ì˜ ì›” ë§¤ì¶œì´ 3ê°œì›” ì—°ì† 15%ì”© ì¦ê°€í–ˆë‹¤. ì²« ë‹¬ ë§¤ì¶œì´ 100ë§Œì›ì´ì—ˆë‹¤ë©´ 3ê°œì›” í›„ ë§¤ì¶œì€?"

response = model.reason(problem)

print(response.reasoning_steps)
# ì¶œë ¥:
# Step 1: ì²« ë‹¬ ë§¤ì¶œ = 100ë§Œì›
# Step 2: ë‘˜ì§¸ ë‹¬ = 100 Ã— 1.15 = 115ë§Œì›  
# Step 3: ì…‹ì§¸ ë‹¬ = 115 Ã— 1.15 = 132.25ë§Œì›
# Step 4: ë„·ì§¸ ë‹¬ = 132.25 Ã— 1.15 = 152.09ë§Œì›
# ë”°ë¼ì„œ 3ê°œì›” í›„ ë§¤ì¶œì€ 152.09ë§Œì›
\`\`\`

### **Multi-Step Verification**
\`\`\`python
# ì¶”ë¡  ê²°ê³¼ ê²€ì¦
verification = model.verify_reasoning(response)
print(verification.confidence_score)  # 0.95
print(verification.potential_errors)   # []
print(verification.alternative_approaches)  # [ë‹¤ë¥¸ í•´ê²° ë°©ë²•ë“¤]
\`\`\`

### **Interactive Reasoning**
\`\`\`python
# ëŒ€í™”í˜• ì¶”ë¡  ê³¼ì •
conversation = model.start_reasoning_session(
    "ê¸°í›„ ë³€í™”ê°€ ë†ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì¤˜"
)

# ì‚¬ìš©ìê°€ ì¤‘ê°„ì— ê°œì… ê°€ëŠ¥
conversation.add_constraint("ë¶ë°˜êµ¬ ì˜¨ëŒ€ ì§€ì—­ì— ì§‘ì¤‘í•´ì¤˜")
conversation.request_clarification("êµ¬ì²´ì ì¸ ë†ì‘ë¬¼ì€ ì–´ë–¤ ê²ƒë“¤?")

final_analysis = conversation.complete_reasoning()
\`\`\`

## ğŸ› ï¸ ê°„ë‹¨í•œ ì„¤ì¹˜ ë° ì‚¬ìš©ë²•

### **ë¡œì»¬ ì„¤ì¹˜**
\`\`\`bash
# GitHubì—ì„œ í´ë¡ 
git clone https://github.com/open-r1/open-r1.git
cd open-r1

# Conda í™˜ê²½ ìƒì„±
conda create -n open-r1 python=3.9
conda activate open-r1

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python download_models.py
\`\`\`

### **Docker ì‚¬ìš©**
\`\`\`bash
# Docker ì´ë¯¸ì§€ ì‹¤í–‰
docker pull openr1/open-r1:latest
docker run -p 8000:8000 openr1/open-r1:latest

# API ì„œë²„ ì ‘ê·¼
curl http://localhost:8000/v1/reasoning \\\\
  -H "Content-Type: application/json" \\\\
  -d '{"prompt": "ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•´ì¤˜", "show_reasoning": true}'
\`\`\`

### **Python API ì‚¬ìš©**
\`\`\`python
import open_r1

# ê¸°ë³¸ ì¶”ë¡  ëª¨ë¸ ë¡œë“œ
model = open_r1.load_model("open-r1-7b")

# ì¶”ë¡  ì‹¤í–‰
result = model.generate_with_reasoning(
    prompt="ì™œ ì§€êµ¬ëŠ” ë‘¥ê¸€ê¹Œ?",
    max_reasoning_steps=10,
    temperature=0.7,
    show_intermediate_steps=True
)

# ê²°ê³¼ í™•ì¸
print("ìµœì¢… ë‹µë³€:", result.final_answer)
print("ì¶”ë¡  ê³¼ì •:", result.reasoning_trace)
print("ì‹ ë¢°ë„:", result.confidence)
\`\`\`

## ğŸ”¬ DeepSeek R1ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ

### **ì¶”ë¡  ëŠ¥ë ¥ ë²¤ì¹˜ë§ˆí¬**
| í‰ê°€ í•­ëª© | Open R1 | DeepSeek R1 | GPT-4 |
|-----------|---------|-------------|-------|
| **ìˆ˜í•™ ë¬¸ì œ í•´ê²°** | 87% | 92% | 88% |
| **ë…¼ë¦¬ì  ì¶”ë¡ ** | 84% | 89% | 86% |
| **ê³¼í•™ì  ì¶”ë¡ ** | 82% | 88% | 83% |
| **íˆ¬ëª…ì„±** | 100% | 30% | 0% |
| **ë¹„ìš©** | ë¬´ë£Œ | ìœ ë£Œ | ìœ ë£Œ |

### **ì‹¤ì œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**
**ë³µì¡í•œ ë…¼ë¦¬ í¼ì¦ í•´ê²°**:
- âœ… Open R1: ë‹¨ê³„ë³„ ëª…í™•í•œ ì¶”ë¡  ê³¼ì • ì œì‹œ
- âš ï¸ DeepSeek R1: ê²°ê³¼ëŠ” ì •í™•í•˜ì§€ë§Œ ê³¼ì • ë¶ˆíˆ¬ëª…
- âŒ GPT-4: ì¶”ë¡  ê³¼ì • ì „í˜€ ê³µê°œë˜ì§€ ì•ŠìŒ

## ğŸ’¡ ì‹¤ì œ í™œìš© ì‚¬ë¡€ ë° ì‘ìš© ë¶„ì•¼

### **êµìœ¡ ë¶„ì•¼**
**ìˆ˜í•™ êµìœ¡ ë„êµ¬**:
\`\`\`python
# ë‹¨ê³„ë³„ ë¬¸ì œ í•´ê²° ì„¤ëª…
math_tutor = open_r1.MathTutor()
explanation = math_tutor.solve_with_explanation(
    "2x + 3 = 11, xëŠ” ë¬´ì—‡ì¸ê°€?"
)

# í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ê³„ë³„ ì„¤ëª… ì œê³µ
print(explanation.step_by_step_solution)
\`\`\`

### **ì—°êµ¬ ë¶„ì•¼**
**ê°€ì„¤ ê²€ì¦**:
\`\`\`python
# ê³¼í•™ì  ê°€ì„¤ ë¶„ì„
researcher = open_r1.ResearchAssistant()
analysis = researcher.analyze_hypothesis(
    "ì‹ë¬¼ì˜ ì„±ì¥ ì†ë„ëŠ” ìŒì•…ì— ì˜í–¥ì„ ë°›ëŠ”ë‹¤",
    available_evidence=["ì—°êµ¬ë…¼ë¬¸1.pdf", "ì‹¤í—˜ë°ì´í„°.csv"]
)

print(analysis.supporting_evidence)
print(analysis.contradicting_evidence)
print(analysis.confidence_level)
\`\`\`

### **ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •**
**ì „ëµì  ë¶„ì„**:
\`\`\`python
# ì‚¬ì—… ê²°ì • ë¶„ì„
business_analyzer = open_r1.BusinessAnalyzer()
recommendation = business_analyzer.analyze_decision(
    "ìƒˆë¡œìš´ ì œí’ˆ ì¶œì‹œ vs ê¸°ì¡´ ì œí’ˆ ê°œì„ ",
    context={"budget": 1000000, "timeline": "6months", "market": "tech"}
)

print(recommendation.pros_and_cons)
print(recommendation.risk_assessment)
print(recommendation.final_recommendation)
\`\`\`

## ğŸŒ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì™€ ìƒíƒœê³„

### **GitHub í†µê³„** (2025ë…„ 1ì›” ê¸°ì¤€)
- â­ **25.2K+ Stars**
- ğŸ”€ **2.4K+ Forks** 
- ğŸ‘¥ **200+ Contributors**
- ğŸ“ˆ **ì¼ì¼ 500+ ë‹¤ìš´ë¡œë“œ**

### **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬**
1. **ëª¨ë¸ ìµœì í™”**: ì¶”ë¡  ì†ë„ 2ë°° í–¥ìƒ
2. **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ì¶”ê°€
3. **í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ**: ë„ë©”ì¸ë³„ íŠ¹í™” ëª¨ë“ˆ
4. **êµìœ¡ ìë£Œ**: íŠœí† ë¦¬ì–¼, ì˜ˆì œ, ë¬¸ì„œí™”

### **Hugging Face ì£¼ë„ ê°œë°œ**
- ğŸ“ **ì—°êµ¬ ê¸°ê´€**: Hugging Face Research Team ì£¼ë„
- ğŸ¢ **ê¸°ì—… íŒŒíŠ¸ë„ˆì‹­**: íˆ¬ëª… AIë¥¼ ì¤‘ì‹œí•˜ëŠ” ê¸€ë¡œë²Œ ê¸°ì—…ë“¤
- ğŸŒ **ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°**: ì „ ì„¸ê³„ ê°œë°œìë“¤ì˜ ì ê·¹ì  ì°¸ì—¬

## ğŸ”® ê¸°ìˆ ì  í˜ì‹ ê³¼ ì°¨ë³„í™” ìš”ì†Œ

### **Explainable AI (XAI) í†µí•©**
- **ì‹œê°í™”**: ì¶”ë¡  ê³¼ì • ê·¸ë˜í”„ í‘œí˜„
- **ìƒí˜¸ì‘ìš©**: ì‚¬ìš©ìê°€ ì¶”ë¡  ê²½ë¡œ ìˆ˜ì • ê°€ëŠ¥
- **ê²€ì¦**: ê° ë‹¨ê³„ë³„ ì‹ ë¢°ë„ í‰ê°€

### **ë¶„ì‚° ì»´í“¨íŒ… ì§€ì›**
\`\`\`python
# ì—¬ëŸ¬ GPUì—ì„œ ë³‘ë ¬ ì¶”ë¡ 
distributed_model = open_r1.DistributedReasoning(
    nodes=["gpu1", "gpu2", "gpu3"],
    reasoning_strategy="parallel_chains"
)

result = distributed_model.solve_complex_problem(problem)
\`\`\`

### **ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ ê°€ëŠ¥í•œ ì¶”ë¡  ì „ëµ**
\`\`\`python
# ì‚¬ìš©ì ì •ì˜ ì¶”ë¡  ë°©ë²•
custom_strategy = open_r1.ReasoningStrategy(
    approach="scientific_method",
    steps=["hypothesis", "evidence", "analysis", "conclusion"],
    verification_level="high"
)

model.set_reasoning_strategy(custom_strategy)
\`\`\`

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”ì™€ í™•ì¥ì„±

### **í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­**
- **ìµœì†Œ**: 8GB RAM, GTX 1660 
- **ê¶Œì¥**: 16GB RAM, RTX 3080
- **ìµœì **: 32GB RAM, RTX 4090

### **ì²˜ë¦¬ ì„±ëŠ¥**
- **7B ëª¨ë¸**: ì´ˆë‹¹ 50 í† í° ìƒì„±
- **13B ëª¨ë¸**: ì´ˆë‹¹ 30 í† í° ìƒì„±  
- **70B ëª¨ë¸**: ì´ˆë‹¹ 10 í† í° ìƒì„± (ë¶„ì‚° ì²˜ë¦¬)

## ğŸš€ í–¥í›„ ë°œì „ ë°©í–¥ê³¼ ë¡œë“œë§µ

### **2025ë…„ ê³„íš**
1. **Q1**: GPT-4 ìˆ˜ì¤€ ì„±ëŠ¥ ë‹¬ì„±
2. **Q2**: ì‹¤ì‹œê°„ ì¶”ë¡  ìµœì í™”
3. **Q3**: ëª¨ë°”ì¼ ë²„ì „ ì¶œì‹œ
4. **Q4**: í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ëŸ°ì¹˜

### **ì¥ê¸° ë¹„ì „**
- **AI ë¯¼ì£¼í™”**: ëˆ„êµ¬ë‚˜ ê³ ì„±ëŠ¥ ì¶”ë¡  AI ì ‘ê·¼
- **íˆ¬ëª…ì„± í‘œì¤€**: AI ì¶”ë¡ ì˜ ìƒˆë¡œìš´ í‘œì¤€ ì œì‹œ
- **êµìœ¡ í˜ì‹ **: AI ê¸°ë°˜ ê°œì¸í™” êµìœ¡ ì‹¤í˜„

## ğŸ¯ Open R1ì„ ì„ íƒí•´ì•¼ í•˜ëŠ” ì´ìœ 

### **ê¸°ìˆ ì  ìš°ìœ„**
1. **ì™„ì „í•œ íˆ¬ëª…ì„±**: ëª¨ë“  ì¶”ë¡  ê³¼ì • ê³µê°œ
2. **ë†’ì€ ì„±ëŠ¥**: ìƒìš© ëª¨ë¸ê³¼ ê²½ìŸí•˜ëŠ” ì •í™•ë„
3. **í™•ì¥ ê°€ëŠ¥ì„±**: ì»¤ìŠ¤í„°ë§ˆì´ì§•ê³¼ í™•ì¥ ìš©ì´
4. **ì»¤ë®¤ë‹ˆí‹°**: í™œë°œí•œ ê°œë°œì ìƒíƒœê³„

### **ì‹¤ìš©ì  ì¥ì **
1. **ë¹„ìš© íš¨ìœ¨ì„±**: ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥
2. **ë°ì´í„° í”„ë¼ì´ë²„ì‹œ**: ë¡œì»¬ ì‹¤í–‰ ê°€ëŠ¥
3. **ì‹ ë¢°ì„±**: ê²€ì¦ ê°€ëŠ¥í•œ ì¶”ë¡  ê³¼ì •
4. **êµìœ¡ì  ê°€ì¹˜**: í•™ìŠµê³¼ ì—°êµ¬ì— ìµœì 

## ğŸ’» ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!

**GitHub**: https://github.com/huggingface/open-r1
**Hugging Face**: https://huggingface.co/blog/open-r1
**ë¬¸ì„œ**: https://github.com/huggingface/open-r1/blob/main/README.md
**ì»¤ë®¤ë‹ˆí‹°**: https://discord.gg/hugging-face

Open R1ì€ ë‹¨ìˆœí•œ AI ëª¨ë¸ì´ ì•„ë‹™ë‹ˆë‹¤. **íˆ¬ëª…í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AIì˜ ë¯¸ë˜**ë¥¼ ë§Œë“¤ì–´ê°€ëŠ” í˜ì‹ ì ì¸ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

**AI ë¯¼ì£¼í™”ì˜ ìƒˆë¡œìš´ ì‹œëŒ€ì— í•¨ê»˜í•˜ì„¸ìš”!** ğŸ¤–âœ¨

---

*ğŸ¤– Open R1ì˜ íˆ¬ëª…í•œ AIê°€ ê¶ê¸ˆí•˜ë‹¤ë©´, ì¢‹ì•„ìš”ì™€ ëŒ“ê¸€ë¡œ ì—¬ëŸ¬ë¶„ì˜ AI ì¶”ë¡  ê²½í—˜ì„ ê³µìœ í•´ì£¼ì„¸ìš”!*`

  const excerpt =
    'Hugging Face Open R1ì´ DeepSeek R1 ì™„ì „ ì¬í˜„! 25.2K+ ìŠ¤íƒ€ ê¸°ë¡í•˜ë©° íˆ¬ëª…í•œ ì¶”ë¡  ê³¼ì •ê³¼ ë¬´ë£Œ ì ‘ê·¼ì„±ìœ¼ë¡œ AI ë¯¼ì£¼í™”ë¥¼ ì‹¤í˜„í•˜ëŠ” í˜ì‹ ì  í”„ë¡œì íŠ¸ë¥¼ ì™„ì „ ë¶„ì„í•©ë‹ˆë‹¤.'

  const slug = 'open-r1-transparent-reasoning-ai-opensource-alternative'

  try {
    const post = await prisma.mainPost.create({
      data: {
        title,
        content,
        excerpt,
        slug,
        status: PostStatus.PUBLISHED,
        isPinned: false,
        authorId,
        authorRole: GlobalRole.ADMIN,
        categoryId,
        approvedAt: new Date(),
        approvedById: authorId,
        rejectedReason: null,
        metaTitle:
          'Open R1: Hugging Face DeepSeek R1 ì™„ì „ ì¬í˜„ 25.2K Stars - íˆ¬ëª… AI í˜ì‹ ',
        metaDescription: excerpt,
        viewCount: getRandomViewCount(150, 300),
        likeCount: 0,
        commentCount: 0,
      },
    })

    // ê´€ë ¨ íƒœê·¸ ìƒì„± ë° ì—°ê²° (ìµœëŒ€ 5ê°œ)
    const tags = [
      { name: 'Open R1', slug: 'open-r1', color: '#10a37f' },
      { name: 'AI ì¶”ë¡ ', slug: 'ai-reasoning', color: '#8b5cf6' },
      { name: 'DeepSeek ëŒ€ì•ˆ', slug: 'deepseek-alternative', color: '#dc2626' },
      { name: 'ì˜¤í”ˆì†ŒìŠ¤ 2025', slug: 'opensource-2025', color: '#3b82f6' },
      { name: 'íˆ¬ëª…í•œ AI', slug: 'transparent-ai', color: '#059669' },
    ]

    for (const tagData of tags) {
      const tag = await prisma.mainTag.upsert({
        where: { slug: tagData.slug },
        update: { postCount: { increment: 1 } },
        create: {
          ...tagData,
          postCount: 1,
        },
      })

      await prisma.mainPostTag.create({
        data: {
          postId: post.id,
          tagId: tag.id,
        },
      })
    }

    console.log(`âœ… "${title}" ê²Œì‹œê¸€ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!`)
    console.log(`ğŸ“Š ì¡°íšŒìˆ˜: ${post.viewCount}`)
    console.log(`ğŸ“ ê²Œì‹œê¸€ ID: ${post.id}`)
    console.log(`ğŸ”— ìŠ¬ëŸ¬ê·¸: ${post.slug}`)
    console.log(`ğŸ·ï¸ ${tags.length}ê°œì˜ íƒœê·¸ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.`)

    return post
  } catch (error) {
    console.error('ê²Œì‹œê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error)
    throw error
  } finally {
    await prisma.$disconnect()
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
createOpenR1ReasoningAiPost()
  .then(() => {
    console.log('ğŸ‰ Open R1 ì¶”ë¡  AI ì˜¤í”ˆì†ŒìŠ¤ ê²Œì‹œê¸€ ìƒì„± ì™„ë£Œ!')
    process.exit(0)
  })
  .catch((error) => {
    console.error('âŒ ì‹¤í–‰ ì˜¤ë¥˜:', error)
    process.exit(1)
  })
